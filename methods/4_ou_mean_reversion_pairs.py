"""
4) OU(Ornstein-Uhlenbeck) í‰ê· íšŒê·€ ì†ë„ ê¸°ë°˜ - ì†ë„ë¡œ í’ˆì§ˆ ì„ ë³„
í•µì‹¬: ìŠ¤í”„ë ˆë“œê°€ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ í‰ê· ìœ¼ë¡œ ëŒì•„ì˜¤ëŠ”ê°€(ì†ë„/ë°˜ê°ê¸°)ë¡œ í˜ì–´ë¥¼ í•„í„°ë§
"""
import pandas as pd
import numpy as np
from typing import List, Tuple, Dict
from scipy.optimize import minimize
import os
import sys
import importlib.util

# ê³µí†µ ìœ í‹¸ë¦¬í‹° ë™ì  import
def import_common_utils():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    utils_path = os.path.join(os.path.dirname(current_dir), "utils", "common_utils.py")
    spec = importlib.util.spec_from_file_location("common_utils", utils_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

# ê³µí†µ í•¨ìˆ˜ë“¤ import
common_utils = import_common_utils()
load_data = common_utils.load_data
normalize_prices = common_utils.normalize_prices
calculate_spread = common_utils.calculate_spread
calculate_zscore = common_utils.calculate_zscore
calculate_half_life = common_utils.calculate_half_life
generate_trading_signals = common_utils.generate_trading_signals
calculate_transaction_cost_ratio = common_utils.calculate_transaction_cost_ratio
calculate_hedge_ratio_ols = common_utils.calculate_hedge_ratio_ols

class OUMeanReversionPairTrading:
    def __init__(self, formation_window: int = 252, signal_window: int = 60,
                 enter_threshold: float = 2.0, exit_threshold: float = 0.5,
                 stop_loss: float = 3.0, min_half_life: int = 5, max_half_life: int = 60,
                 min_cost_ratio: float = 5.0, min_mean_reversion_speed: float = 0.01):
        """
        OU í‰ê· íšŒê·€ ì†ë„ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© íŒŒë¼ë¯¸í„°
        
        Args:
            formation_window: í˜ì–´ ì„ ì • ê¸°ê°„ (ì˜ì—…ì¼)
            signal_window: z-ìŠ¤ì½”ì–´ ê³„ì‚° ë¡¤ë§ ìœˆë„ìš°
            enter_threshold: ì§„ì… z-ìŠ¤ì½”ì–´ ì„ê³„ê°’
            exit_threshold: ì²­ì‚° z-ìŠ¤ì½”ì–´ ì„ê³„ê°’
            stop_loss: ì†ì ˆ z-ìŠ¤ì½”ì–´ ì„ê³„ê°’
            min_half_life: ìµœì†Œ ë°˜ê°ê¸° (ì˜ì—…ì¼)
            max_half_life: ìµœëŒ€ ë°˜ê°ê¸° (ì˜ì—…ì¼)
            min_cost_ratio: ìµœì†Œ 1Ïƒ/ê±°ë˜ë¹„ìš© ë¹„ìœ¨
            min_mean_reversion_speed: ìµœì†Œ í‰ê· íšŒê·€ ì†ë„ (Îº)
        """
        self.formation_window = formation_window
        self.signal_window = signal_window
        self.enter_threshold = enter_threshold
        self.exit_threshold = exit_threshold
        self.stop_loss = stop_loss
        self.min_half_life = min_half_life
        self.max_half_life = max_half_life
        self.min_cost_ratio = min_cost_ratio
        self.min_mean_reversion_speed = min_mean_reversion_speed
    
    def fit_ou_process_ar1(self, spread: pd.Series) -> Tuple[float, float, float]:
        """
        AR(1) ëª¨ë¸ë¡œ OU í”„ë¡œì„¸ìŠ¤ íŒŒë¼ë¯¸í„° ì¶”ì •
        S_t = Ï† * S_{t-1} + Îµ_t
        OU íŒŒë¼ë¯¸í„°: Îº = -ln(Ï†), half_life = ln(2)/Îº
        
        Returns:
            (kappa, half_life, phi): í‰ê· íšŒê·€ ì†ë„, ë°˜ê°ê¸°, AR(1) ê³„ìˆ˜
        """
        try:
            spread_clean = spread.dropna()
            if len(spread_clean) < 30:
                return 0, np.inf, 1
            
            spread_diff = spread_clean.diff().dropna()
            spread_lag = spread_clean.shift(1).dropna()
            
            # ê¸¸ì´ ë§ì¶”ê¸°
            min_len = min(len(spread_diff), len(spread_lag))
            spread_diff = spread_diff[-min_len:]
            spread_lag = spread_lag[-min_len:]
            
            # AR(1): Î”S_t = Î± + (Ï†-1) * S_{t-1} + Îµ_t
            X = np.column_stack([np.ones(len(spread_lag)), spread_lag.values])
            y = spread_diff.values
            
            beta = np.linalg.lstsq(X, y, rcond=None)[0]
            phi = beta[1] + 1  # Ï† = 1 + (Ï†-1)
            
            if phi >= 1 or phi <= 0:
                return 0, np.inf, phi
                
            kappa = -np.log(phi)
            half_life = np.log(2) / kappa if kappa > 0 else np.inf
            
            return kappa, half_life, phi
            
        except Exception:
            return 0, np.inf, 1
    
    def fit_ou_process_mle(self, spread: pd.Series, dt: float = 1.0/252) -> Tuple[float, float, float, float]:
        """
        ìµœëŒ€ìš°ë„ë²•(MLE)ìœ¼ë¡œ OU í”„ë¡œì„¸ìŠ¤ íŒŒë¼ë¯¸í„° ì¶”ì •
        dS_t = Îº(Î¼ - S_t)dt + Ïƒ dW_t
        
        Args:
            spread: ìŠ¤í”„ë ˆë“œ ì‹œê³„ì—´
            dt: ì‹œê°„ ê°„ê²© (ì¼ ë‹¨ìœ„, ê¸°ë³¸ê°’: 1ì˜ì—…ì¼ = 1/252ë…„)
            
        Returns:
            (kappa, mu, sigma, half_life): í‰ê· íšŒê·€ ì†ë„, ì¥ê¸° í‰ê· , ë³€ë™ì„±, ë°˜ê°ê¸°
        """
        try:
            spread_clean = spread.dropna()
            if len(spread_clean) < 50:
                return 0, spread_clean.mean(), spread_clean.std(), np.inf
            
            def neg_log_likelihood(params):
                kappa, mu, sigma = params
                if kappa <= 0 or sigma <= 0:
                    return 1e10
                
                n = len(spread_clean)
                log_likelihood = 0
                
                for i in range(1, n):
                    s_prev = spread_clean.iloc[i-1]
                    s_curr = spread_clean.iloc[i]
                    
                    # OU í”„ë¡œì„¸ìŠ¤ì˜ ì¡°ê±´ë¶€ ë¶„í¬
                    mean = s_prev * np.exp(-kappa * dt) + mu * (1 - np.exp(-kappa * dt))
                    variance = (sigma**2) * (1 - np.exp(-2 * kappa * dt)) / (2 * kappa)
                    
                    if variance <= 0:
                        return 1e10
                    
                    # ë¡œê·¸ ìš°ë„
                    log_likelihood += -0.5 * np.log(2 * np.pi * variance) - \
                                     (s_curr - mean)**2 / (2 * variance)
                
                return -log_likelihood
            
            # ì´ˆê¸°ê°’ ì„¤ì •
            initial_mu = spread_clean.mean()
            initial_sigma = spread_clean.std()
            initial_kappa = 0.1  # ì ë‹¹í•œ í‰ê· íšŒê·€ ì†ë„
            
            # ì œì•½ì¡°ê±´
            bounds = [(1e-6, 10), (-10, 10), (1e-6, 10)]  # (kappa, mu, sigma)
            initial_guess = [initial_kappa, initial_mu, initial_sigma]
            
            result = minimize(neg_log_likelihood, initial_guess, bounds=bounds, 
                            method='L-BFGS-B')
            
            if result.success:
                kappa, mu, sigma = result.x
                half_life = np.log(2) / kappa if kappa > 0 else np.inf
                return kappa, mu, sigma, half_life
            else:
                return 0, initial_mu, initial_sigma, np.inf
                
        except Exception:
            return 0, spread.mean() if len(spread) > 0 else 0, \
                   spread.std() if len(spread) > 0 else 1, np.inf
    
    def calculate_ou_quality_score(self, kappa: float, half_life: float, sigma: float) -> float:
        """
        OU í”„ë¡œì„¸ìŠ¤ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        ë†’ì€ í‰ê· íšŒê·€ ì†ë„, ì ë‹¹í•œ ë°˜ê°ê¸°, ë‚®ì€ ë³€ë™ì„± ì„ í˜¸
        
        Returns:
            quality_score: 0~100 ì ìˆ˜
        """
        score = 0
        
        # 1. í‰ê· íšŒê·€ ì†ë„ ì ìˆ˜ (Îº)
        if kappa >= self.min_mean_reversion_speed:
            kappa_score = min(100, kappa * 500)  # Îº=0.2ì´ë©´ 100ì 
            score += kappa_score * 0.4
        
        # 2. ë°˜ê°ê¸° ì ìˆ˜
        if self.min_half_life <= half_life <= self.max_half_life:
            # ìµœì  ë°˜ê°ê¸°: 20ì¼ ì •ë„
            optimal_hl = 20
            hl_score = max(0, 100 - abs(half_life - optimal_hl) * 2)
            score += hl_score * 0.4
        
        # 3. ì•ˆì •ì„± ì ìˆ˜ (ë³€ë™ì„± ì—­ìˆ˜)
        if sigma > 0:
            stability_score = min(100, 50 / sigma)
            score += stability_score * 0.2
        
        return score
    
    def select_pairs(self, prices: pd.DataFrame, n_pairs: int = 20) -> List[Dict]:
        """
        OU í‰ê· íšŒê·€ ì†ë„ ê¸°ë°˜ í˜ì–´ ì„ ì •
        
        Args:
            prices: ê°€ê²© ë°ì´í„°
            n_pairs: ì„ ì •í•  í˜ì–´ ê°œìˆ˜
            
        Returns:
            ì„ ì •ëœ í˜ì–´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        # ìµœê·¼ formation_window ê¸°ê°„ ë°ì´í„° ì¶”ì¶œ
        formation_data = prices.tail(self.formation_window)
        
        # ê²°ì¸¡ì¹˜ê°€ ë§ì€ ìì‚° ì œì™¸
        valid_assets = []
        for col in formation_data.columns:
            if formation_data[col].notna().sum() >= self.formation_window * 0.9:
                valid_assets.append(col)
        
        if len(valid_assets) < 2:
            return []
            
        formation_data = formation_data[valid_assets].fillna(method='ffill')
        
        # OU í”„ë¡œì„¸ìŠ¤ ë¶„ì„ ê²°ê³¼
        ou_results = []
        
        for i, asset1 in enumerate(valid_assets):
            for j, asset2 in enumerate(valid_assets):
                if i >= j:  # ì¤‘ë³µ ë°©ì§€
                    continue
                
                # OLS í—¤ì§€ë¹„ìœ¨ ì¶”ì •
                hedge_ratio, p_value, residuals = calculate_hedge_ratio_ols(
                    formation_data[asset1], formation_data[asset2]
                )
                
                if len(residuals) < 50:  # ìµœì†Œ í‘œë³¸ ìˆ˜
                    continue
                
                # AR(1) ë°©ë²•ìœ¼ë¡œ OU íŒŒë¼ë¯¸í„° ì¶”ì •
                kappa_ar1, half_life_ar1, phi = self.fit_ou_process_ar1(residuals)
                
                # MLE ë°©ë²•ìœ¼ë¡œ OU íŒŒë¼ë¯¸í„° ì¶”ì •
                kappa_mle, mu, sigma, half_life_mle = self.fit_ou_process_mle(residuals)
                
                # ë‘ ë°©ë²• ê²°ê³¼ í‰ê· 
                kappa_avg = (kappa_ar1 + kappa_mle) / 2
                half_life_avg = (half_life_ar1 + half_life_mle) / 2
                
                # ê±°ë˜ë¹„ìš© ëŒ€ë¹„ ìˆ˜ìµì„±
                cost_ratio = calculate_transaction_cost_ratio(residuals)
                
                # OU í’ˆì§ˆ ì ìˆ˜
                quality_score = self.calculate_ou_quality_score(kappa_avg, half_life_avg, sigma)
                
                # í•„í„°ë§ ì¡°ê±´
                if (self.min_half_life <= half_life_avg <= self.max_half_life and
                    cost_ratio >= self.min_cost_ratio and
                    kappa_avg >= self.min_mean_reversion_speed and
                    quality_score >= 30):  # ìµœì†Œ í’ˆì§ˆ ì ìˆ˜
                    
                    ou_results.append({
                        'asset1': asset1,
                        'asset2': asset2,
                        'hedge_ratio': hedge_ratio,
                        'p_value': p_value,
                        'kappa_ar1': kappa_ar1,
                        'kappa_mle': kappa_mle,
                        'kappa_avg': kappa_avg,
                        'half_life_ar1': half_life_ar1,
                        'half_life_mle': half_life_mle,
                        'half_life_avg': half_life_avg,
                        'mu': mu,
                        'sigma': sigma,
                        'cost_ratio': cost_ratio,
                        'quality_score': quality_score,
                        'method': 'ou_mean_reversion'
                    })
        
        # í’ˆì§ˆ ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        ou_results.sort(key=lambda x: x['quality_score'], reverse=True)
        
        # ì¤‘ë³µ ì—†ëŠ” í˜ì–´ ì„ ì •
        selected_pairs = []
        used_assets = set()
        
        for result in ou_results:
            if len(selected_pairs) >= n_pairs:
                break
                
            asset1, asset2 = result['asset1'], result['asset2']
            if asset1 not in used_assets and asset2 not in used_assets:
                selected_pairs.append(result)
                used_assets.add(asset1)
                used_assets.add(asset2)
        
        return selected_pairs
    
    def calculate_time_stop(self, half_life: float, multiplier: float = 2.0) -> int:
        """
        ë°˜ê°ê¸° ê¸°ë°˜ íƒ€ì„ìŠ¤íƒ‘ ê³„ì‚°
        
        Args:
            half_life: ë°˜ê°ê¸° (ì˜ì—…ì¼)
            multiplier: ë°˜ê°ê¸° ë°°ìˆ˜ (ê¸°ë³¸ê°’: 2ë°°)
            
        Returns:
            time_stop: íƒ€ì„ìŠ¤íƒ‘ ì¼ìˆ˜
        """
        return int(half_life * multiplier) if half_life != np.inf else 60
    
    def generate_signals(self, prices: pd.DataFrame, pair_info: Dict) -> Dict:
        """
        íŠ¹ì • í˜ì–´ì— ëŒ€í•œ íŠ¸ë ˆì´ë”© ì‹ í˜¸ ìƒì„±
        
        Args:
            prices: ì „ì²´ ê°€ê²© ë°ì´í„°
            pair_info: í˜ì–´ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ì‹ í˜¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        asset1, asset2 = pair_info['asset1'], pair_info['asset2']
        
        # ìµœê·¼ ë°ì´í„° í™•ë³´
        recent_data = prices[[asset1, asset2]].tail(self.signal_window * 2).fillna(method='ffill')
        
        if len(recent_data) < self.signal_window:
            return {'status': 'insufficient_data'}
        
        # ìŠ¤í”„ë ˆë“œ ê³„ì‚°
        spread = calculate_spread(
            recent_data[asset1],
            recent_data[asset2],
            hedge_ratio=pair_info['hedge_ratio']
        )
        
        # Z-ìŠ¤ì½”ì–´ ê³„ì‚°
        zscore = calculate_zscore(spread, window=self.signal_window)
        current_zscore = zscore.iloc[-1] if not zscore.empty else 0
        
        # ì‹ í˜¸ ìƒì„±
        signals = generate_trading_signals(
            zscore, 
            enter_threshold=self.enter_threshold,
            exit_threshold=self.exit_threshold,
            stop_loss=self.stop_loss
        )
        
        current_signal = signals.iloc[-1] if not signals.empty else 0
        
        # íƒ€ì„ìŠ¤íƒ‘ ê³„ì‚°
        time_stop = self.calculate_time_stop(pair_info['half_life_avg'])
        
        # ì‹ í˜¸ í•´ì„
        if current_signal == 1:
            signal_type = "ENTER_LONG"
            direction = f"Long {asset1}, Short {asset2} (ratio: {pair_info['hedge_ratio']:.3f})"
        elif current_signal == -1:
            signal_type = "ENTER_SHORT"
            direction = f"Short {asset1}, Long {asset2} (ratio: {pair_info['hedge_ratio']:.3f})"
        else:
            signal_type = "EXIT_OR_WAIT"
            direction = "Exit or Wait"
        
        return {
            'status': 'success',
            'pair': f"{asset1}-{asset2}",
            'signal_type': signal_type,
            'direction': direction,
            'current_zscore': current_zscore,
            'kappa_avg': pair_info['kappa_avg'],
            'half_life_avg': pair_info['half_life_avg'],
            'quality_score': pair_info['quality_score'],
            'time_stop': time_stop,
            'hedge_ratio': pair_info['hedge_ratio'],
            'cost_ratio': pair_info['cost_ratio'],
            'method': 'ou_mean_reversion'
        }
    
    def screen_pairs(self, prices: pd.DataFrame, n_pairs: int = 10) -> Tuple[List[Dict], List[Dict]]:
        """
        ì „ì²´ í˜ì–´ ìŠ¤í¬ë¦¬ë‹ ë° ì‹ í˜¸ ìƒì„±
        
        Returns:
            (enter_signals, watch_signals): ì§„ì… ì‹ í˜¸ì™€ ê´€ì°° ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸
        """
        # í˜ì–´ ì„ ì •
        selected_pairs = self.select_pairs(prices, n_pairs * 2)
        
        enter_signals = []
        watch_signals = []
        
        for pair_info in selected_pairs:
            signal_result = self.generate_signals(prices, pair_info)
            
            if signal_result['status'] != 'success':
                continue
                
            current_z = abs(signal_result['current_zscore'])
            
            # ì§„ì… ì‹ í˜¸ (|z| >= 2.0)
            if current_z >= self.enter_threshold:
                enter_signals.append(signal_result)
            # ê´€ì°° ëŒ€ìƒ (1.5 <= |z| < 2.0)
            elif 1.5 <= current_z < self.enter_threshold:
                watch_signals.append(signal_result)
        
        # í’ˆì§ˆ ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        enter_signals.sort(key=lambda x: x['quality_score'], reverse=True)
        watch_signals.sort(key=lambda x: x['quality_score'], reverse=True)
        
        return enter_signals[:n_pairs], watch_signals[:n_pairs]

def main():
    """
    OU í‰ê· íšŒê·€ ì†ë„ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© ì‹¤í–‰ ì˜ˆì œ
    """
    # ë°ì´í„° ë¡œë”©
    file_path = "/Users/a/PycharmProjects/pair_trading_signal/data/MU Price(BBG).csv"
    prices = load_data(file_path)
    
    # OU í‰ê· íšŒê·€ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© ê°ì²´ ìƒì„±
    ou_trader = OUMeanReversionPairTrading(
        formation_window=252,         # 1ë…„
        signal_window=60,             # 3ê°œì›”
        enter_threshold=2.0,
        exit_threshold=0.5,
        stop_loss=3.0,
        min_half_life=5,
        max_half_life=60,
        min_cost_ratio=5.0,
        min_mean_reversion_speed=0.01  # ìµœì†Œ í‰ê· íšŒê·€ ì†ë„
    )
    
    # í˜ì–´ ìŠ¤í¬ë¦¬ë‹
    enter_list, watch_list = ou_trader.screen_pairs(prices, n_pairs=10)
    
    print("=" * 75)
    print("OU í‰ê· íšŒê·€ ì†ë„ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© ì‹ í˜¸")
    print("=" * 75)
    
    print(f"\nğŸ“ˆ ì§„ì… ì‹ í˜¸ ({len(enter_list)}ê°œ):")
    print("-" * 65)
    for i, signal in enumerate(enter_list, 1):
        print(f"{i:2d}. {signal['pair']:20s} | {signal['direction']:35s}")
        print(f"     Z-Score: {signal['current_zscore']:6.2f} | Half-Life: {signal['half_life_avg']:4.1f}D")
        print(f"     Îº (í‰ê· íšŒê·€ì†ë„): {signal['kappa_avg']:6.4f} | í’ˆì§ˆì ìˆ˜: {signal['quality_score']:5.1f}")
        print(f"     íƒ€ì„ìŠ¤íƒ‘: {signal['time_stop']:2d}ì¼ | ë¹„ìš©ë¹„ìœ¨: {signal['cost_ratio']:5.1f}")
        print(f"     í—¤ì§€ë¹„ìœ¨: {signal['hedge_ratio']:6.3f}")
        print()
    
    print(f"\nğŸ‘€ ê´€ì°° ëŒ€ìƒ ({len(watch_list)}ê°œ):")
    print("-" * 65)
    for i, signal in enumerate(watch_list, 1):
        print(f"{i:2d}. {signal['pair']:20s} | Z-Score: {signal['current_zscore']:6.2f}")
        print(f"     Îº: {signal['kappa_avg']:6.4f} | Half-Life: {signal['half_life_avg']:4.1f}D")
        print(f"     í’ˆì§ˆì ìˆ˜: {signal['quality_score']:5.1f} | íƒ€ì„ìŠ¤íƒ‘: {signal['time_stop']:2d}ì¼")
        print()

if __name__ == "__main__":
    main()