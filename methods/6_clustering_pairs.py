"""
5) í´ëŸ¬ìŠ¤í„°ë§/ìµœê·¼ì ‘ ì´ì›ƒ(ê°„ë‹¨ ML) ê¸°ë°˜ - ë™ë¥˜ë¼ë¦¬ ë¬¶ê³ , ê·¸ ì•ˆì—ì„œ í˜ì–´
í•µì‹¬: ë¹„ìŠ·í•œ íŠ¹ì„±ì˜ ìì‚°ì„ í´ëŸ¬ìŠ¤í„°ë¡œ ë¬¶ê³ , í´ëŸ¬ìŠ¤í„° ë‚´ ìµœê·¼ì ‘ ì´ì›ƒì„ í˜ì–´ë¡œ
"""
import pandas as pd
import numpy as np
from typing import List, Tuple, Dict, Optional
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import pairwise_distances
from sklearn.decomposition import PCA
from scipy.cluster.hierarchy import linkage, fcluster
import os
import sys
import importlib.util

# ê³µí†µ ìœ í‹¸ë¦¬í‹° ë™ì  import
def import_common_utils():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    utils_path = os.path.join(os.path.dirname(current_dir), "utils", "common_utils.py")
    spec = importlib.util.spec_from_file_location("common_utils", utils_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

# ê³µí†µ í•¨ìˆ˜ë“¤ import
common_utils = import_common_utils()
load_data = common_utils.load_data
normalize_prices = common_utils.normalize_prices
calculate_spread = common_utils.calculate_spread
calculate_zscore = common_utils.calculate_zscore
calculate_half_life = common_utils.calculate_half_life
generate_trading_signals = common_utils.generate_trading_signals
calculate_transaction_cost_ratio = common_utils.calculate_transaction_cost_ratio
euclidean_distance_matrix = common_utils.euclidean_distance_matrix

class ClusteringPairTrading:
    def __init__(self, formation_window: int = 252, signal_window: int = 60,
                 enter_threshold: float = 2.0, exit_threshold: float = 0.5,
                 stop_loss: float = 3.0, min_half_life: int = 5, max_half_life: int = 60,
                 min_cost_ratio: float = 5.0, n_clusters: int = 8, 
                 clustering_method: str = 'kmeans'):
        """
        í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© íŒŒë¼ë¯¸í„°
        
        Args:
            formation_window: í˜ì–´ ì„ ì • ê¸°ê°„ (ì˜ì—…ì¼)
            signal_window: z-ìŠ¤ì½”ì–´ ê³„ì‚° ë¡¤ë§ ìœˆë„ìš°
            enter_threshold: ì§„ì… z-ìŠ¤ì½”ì–´ ì„ê³„ê°’
            exit_threshold: ì²­ì‚° z-ìŠ¤ì½”ì–´ ì„ê³„ê°’
            stop_loss: ì†ì ˆ z-ìŠ¤ì½”ì–´ ì„ê³„ê°’
            min_half_life: ìµœì†Œ ë°˜ê°ê¸° (ì˜ì—…ì¼)
            max_half_life: ìµœëŒ€ ë°˜ê°ê¸° (ì˜ì—…ì¼)
            min_cost_ratio: ìµœì†Œ 1Ïƒ/ê±°ë˜ë¹„ìš© ë¹„ìœ¨
            n_clusters: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
            clustering_method: 'kmeans' ë˜ëŠ” 'hierarchical'
        """
        self.formation_window = formation_window
        self.signal_window = signal_window
        self.enter_threshold = enter_threshold
        self.exit_threshold = exit_threshold
        self.stop_loss = stop_loss
        self.min_half_life = min_half_life
        self.max_half_life = max_half_life
        self.min_cost_ratio = min_cost_ratio
        self.n_clusters = n_clusters
        self.clustering_method = clustering_method
        self.scaler = StandardScaler()
    
    def extract_features(self, prices: pd.DataFrame) -> pd.DataFrame:
        """
        í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ íŠ¹ì§• ì¶”ì¶œ
        
        Args:
            prices: ê°€ê²© ë°ì´í„°
            
        Returns:
            íŠ¹ì§• ë°ì´í„°í”„ë ˆì„ (ìì‚°ë³„ íŠ¹ì§• ë²¡í„°)
        """
        features_dict = {}
        
        for asset in prices.columns:
            price_series = prices[asset].dropna()
            
            if len(price_series) < 50:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
                continue
            
            returns = price_series.pct_change().dropna()
            
            if len(returns) < 30:
                continue
            
            # 1. ìˆ˜ìµë¥  í†µê³„
            mean_return = returns.mean()
            volatility = returns.std()
            skewness = returns.skew() if len(returns) > 2 else 0
            kurtosis = returns.kurtosis() if len(returns) > 3 else 0
            
            # 2. ê°€ê²© ì¶”ì„¸
            normalized_prices = normalize_prices(price_series.to_frame(), method='rebase')[asset]
            price_trend = (normalized_prices.iloc[-1] - normalized_prices.iloc[0]) / len(normalized_prices)
            
            # 3. ìµœëŒ€ ë‚™í­ (Maximum Drawdown)
            cumulative = (1 + returns).cumprod()
            rolling_max = cumulative.expanding().max()
            drawdown = (cumulative - rolling_max) / rolling_max
            max_drawdown = drawdown.min()
            
            # 4. ë³€ë™ì„± í´ëŸ¬ìŠ¤í„°ë§ (GARCH íš¨ê³¼ ê·¼ì‚¬)
            returns_squared = returns ** 2
            vol_autocorr = returns_squared.autocorr(lag=1) if len(returns_squared) > 1 else 0
            
            # 5. ë² íƒ€ (ì‹œì¥ ëŒ€ë¹„) - SPX Indexë¥¼ ë²¤ì¹˜ë§ˆí¬ë¡œ ì‚¬ìš©
            market_beta = 1.0  # ê¸°ë³¸ê°’
            if 'SPX Index' in prices.columns and asset != 'SPX Index':
                market_returns = prices['SPX Index'].pct_change().dropna()
                common_idx = returns.index.intersection(market_returns.index)
                if len(common_idx) > 30:
                    asset_ret_common = returns[common_idx]
                    market_ret_common = market_returns[common_idx]
                    covariance = np.cov(asset_ret_common, market_ret_common)[0, 1]
                    market_variance = np.var(market_ret_common)
                    market_beta = covariance / market_variance if market_variance > 0 else 1.0
            
            # 6. ê±°ë˜ëŸ‰ í”„ë¡ì‹œ (ê°€ê²© ë³€í™” í¬ê¸°ì˜ ì—­ìˆ˜ë¡œ ê·¼ì‚¬)
            # ì‹¤ì œ ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ê°€ê²© ë³€í™”ì˜ ì¼ê´€ì„±ìœ¼ë¡œ ëŒ€ì²´
            price_consistency = 1 / (volatility + 1e-6)  # ë³€ë™ì„±ì´ ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ
            
            # 7. ìµœê·¼ ëª¨ë©˜í…€ (ë‹¨ê¸° vs ì¤‘ê¸° ìˆ˜ìµë¥ )
            if len(returns) >= 60:
                short_momentum = returns.tail(20).sum()  # ìµœê·¼ 1ê°œì›”
                medium_momentum = returns.tail(60).sum()  # ìµœê·¼ 3ê°œì›”
                momentum_ratio = short_momentum / (medium_momentum + 1e-6)
            else:
                momentum_ratio = 0
            
            features_dict[asset] = {
                'mean_return': mean_return,
                'volatility': volatility,
                'skewness': skewness,
                'kurtosis': kurtosis,
                'price_trend': price_trend,
                'max_drawdown': max_drawdown,
                'vol_autocorr': vol_autocorr,
                'market_beta': market_beta,
                'price_consistency': price_consistency,
                'momentum_ratio': momentum_ratio
            }
        
        features_df = pd.DataFrame(features_dict).T
        
        # ë¬´í•œê°’ì´ë‚˜ NaN ì œê±°
        features_df = features_df.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        return features_df
    
    def perform_clustering(self, features: pd.DataFrame) -> Dict[int, List[str]]:
        """
        í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
        
        Args:
            features: íŠ¹ì§• ë°ì´í„°í”„ë ˆì„
            
        Returns:
            {cluster_id: [asset_list]} í˜•íƒœì˜ í´ëŸ¬ìŠ¤í„° ì •ë³´
        """
        if len(features) < self.n_clusters:
            # í´ëŸ¬ìŠ¤í„° ìˆ˜ë³´ë‹¤ ìì‚°ì´ ì ìœ¼ë©´ ëª¨ë“  ìì‚°ì„ í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„°ë¡œ
            return {0: list(features.index)}
        
        # íŠ¹ì§• í‘œì¤€í™”
        features_scaled = self.scaler.fit_transform(features)
        
        if self.clustering_method == 'kmeans':
            # K-Means í´ëŸ¬ìŠ¤í„°ë§
            kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, 
                          n_init=10, max_iter=300)
            cluster_labels = kmeans.fit_predict(features_scaled)
            
        elif self.clustering_method == 'hierarchical':
            # ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§
            linkage_matrix = linkage(features_scaled, method='ward')
            cluster_labels = fcluster(linkage_matrix, self.n_clusters, criterion='maxclust')
            cluster_labels = cluster_labels - 1  # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì¡°ì •
            
        else:
            raise ValueError("clustering_method must be 'kmeans' or 'hierarchical'")
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ìì‚° ê·¸ë£¹í™”
        clusters = {}
        for i, asset in enumerate(features.index):
            cluster_id = cluster_labels[i]
            if cluster_id not in clusters:
                clusters[cluster_id] = []
            clusters[cluster_id].append(asset)
        
        return clusters
    
    def find_pairs_within_cluster(self, cluster_assets: List[str], prices: pd.DataFrame) -> List[Tuple[str, str, float]]:
        """
        í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ìµœê·¼ì ‘ ì´ì›ƒ í˜ì–´ ì°¾ê¸°
        
        Args:
            cluster_assets: í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ìì‚° ë¦¬ìŠ¤íŠ¸
            prices: ê°€ê²© ë°ì´í„°
            
        Returns:
            (asset1, asset2, distance) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        if len(cluster_assets) < 2:
            return []
        
        # í´ëŸ¬ìŠ¤í„° ë‚´ ìì‚°ë“¤ì˜ ê°€ê²© ë°ì´í„° ì¶”ì¶œ
        cluster_prices = prices[cluster_assets].dropna()
        
        if len(cluster_prices) < 30:  # ì¶©ë¶„í•œ ë°ì´í„° ì—†ìŒ
            return []
        
        # í‘œì¤€í™”ëœ ê°€ê²©ìœ¼ë¡œ ê±°ë¦¬ ê³„ì‚°
        normalized_prices = normalize_prices(cluster_prices, method='rebase')
        distance_matrix = euclidean_distance_matrix(normalized_prices)
        
        # ìµœê·¼ì ‘ ì´ì›ƒ í˜ì–´ ì¶”ì¶œ
        pairs = []
        n_assets = len(cluster_assets)
        
        for i in range(n_assets):
            for j in range(i + 1, n_assets):
                distance = distance_matrix[i][j]
                pairs.append((cluster_assets[i], cluster_assets[j], distance))
        
        # ê±°ë¦¬ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        pairs.sort(key=lambda x: x[2])
        
        return pairs
    
    def select_pairs(self, prices: pd.DataFrame, n_pairs: int = 20) -> List[Dict]:
        """
        í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ í˜ì–´ ì„ ì •
        
        Args:
            prices: ê°€ê²© ë°ì´í„°
            n_pairs: ì„ ì •í•  í˜ì–´ ê°œìˆ˜
            
        Returns:
            ì„ ì •ëœ í˜ì–´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        # ìµœê·¼ formation_window ê¸°ê°„ ë°ì´í„° ì¶”ì¶œ
        formation_data = prices.tail(self.formation_window)
        
        # ê²°ì¸¡ì¹˜ê°€ ë§ì€ ìì‚° ì œì™¸
        valid_assets = []
        for col in formation_data.columns:
            if formation_data[col].notna().sum() >= self.formation_window * 0.8:
                valid_assets.append(col)
        
        if len(valid_assets) < 2:
            return []
            
        formation_data = formation_data[valid_assets].fillna(method='ffill')
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.extract_features(formation_data)
        
        if len(features) < 2:
            return []
        
        # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
        clusters = self.perform_clustering(features)
        
        # ê° í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ í˜ì–´ ì°¾ê¸°
        all_pairs = []
        
        for cluster_id, cluster_assets in clusters.items():
            cluster_pairs = self.find_pairs_within_cluster(cluster_assets, formation_data)
            
            for asset1, asset2, distance in cluster_pairs:
                # ìŠ¤í”„ë ˆë“œ ê³„ì‚° ë° í’ˆì§ˆ ê²€ì‚¬
                spread = calculate_spread(
                    formation_data[asset1], 
                    formation_data[asset2], 
                    hedge_ratio=1.0
                )
                
                half_life = calculate_half_life(spread)
                cost_ratio = calculate_transaction_cost_ratio(spread)
                
                # í’ˆì§ˆ í•„í„°
                if (self.min_half_life <= half_life <= self.max_half_life and 
                    cost_ratio >= self.min_cost_ratio):
                    
                    all_pairs.append({
                        'asset1': asset1,
                        'asset2': asset2,
                        'cluster_id': cluster_id,
                        'distance': distance,
                        'half_life': half_life,
                        'cost_ratio': cost_ratio,
                        'hedge_ratio': 1.0,
                        'method': 'clustering'
                    })
        
        # ê±°ë¦¬ ê¸°ì¤€ ì •ë ¬ í›„ ì¤‘ë³µ ì œê±°
        all_pairs.sort(key=lambda x: x['distance'])
        
        selected_pairs = []
        used_assets = set()
        
        for pair_info in all_pairs:
            if len(selected_pairs) >= n_pairs:
                break
                
            asset1, asset2 = pair_info['asset1'], pair_info['asset2']
            if asset1 not in used_assets and asset2 not in used_assets:
                selected_pairs.append(pair_info)
                used_assets.add(asset1)
                used_assets.add(asset2)
        
        return selected_pairs
    
    def get_cluster_summary(self, prices: pd.DataFrame) -> Dict:
        """
        í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìš”ì•½ ì •ë³´
        
        Returns:
            í´ëŸ¬ìŠ¤í„°ë³„ ìš”ì•½ ì •ë³´
        """
        formation_data = prices.tail(self.formation_window)
        
        valid_assets = [col for col in formation_data.columns 
                       if formation_data[col].notna().sum() >= self.formation_window * 0.8]
        
        if len(valid_assets) < 2:
            return {}
            
        formation_data = formation_data[valid_assets].fillna(method='ffill')
        features = self.extract_features(formation_data)
        
        if len(features) < 2:
            return {}
        
        clusters = self.perform_clustering(features)
        
        cluster_summary = {}
        for cluster_id, assets in clusters.items():
            # í´ëŸ¬ìŠ¤í„° ë‚´ ìì‚°ë“¤ì˜ í‰ê·  íŠ¹ì„±
            cluster_features = features.loc[assets].mean()
            
            cluster_summary[cluster_id] = {
                'assets': assets,
                'n_assets': len(assets),
                'avg_volatility': cluster_features['volatility'],
                'avg_return': cluster_features['mean_return'],
                'avg_beta': cluster_features['market_beta'],
                'avg_momentum': cluster_features['momentum_ratio']
            }
        
        return cluster_summary
    
    def generate_signals(self, prices: pd.DataFrame, pair_info: Dict) -> Dict:
        """
        íŠ¹ì • í˜ì–´ì— ëŒ€í•œ íŠ¸ë ˆì´ë”© ì‹ í˜¸ ìƒì„±
        
        Args:
            prices: ì „ì²´ ê°€ê²© ë°ì´í„°
            pair_info: í˜ì–´ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ì‹ í˜¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        asset1, asset2 = pair_info['asset1'], pair_info['asset2']
        
        # ìµœê·¼ ë°ì´í„° í™•ë³´
        recent_data = prices[[asset1, asset2]].tail(self.signal_window * 2).fillna(method='ffill')
        
        if len(recent_data) < self.signal_window:
            return {'status': 'insufficient_data'}
        
        # ìŠ¤í”„ë ˆë“œ ê³„ì‚°
        spread = calculate_spread(
            recent_data[asset1],
            recent_data[asset2],
            hedge_ratio=pair_info['hedge_ratio']
        )
        
        # Z-ìŠ¤ì½”ì–´ ê³„ì‚°
        zscore = calculate_zscore(spread, window=self.signal_window)
        current_zscore = zscore.iloc[-1] if not zscore.empty else 0
        
        # ì‹ í˜¸ ìƒì„±
        signals = generate_trading_signals(
            zscore, 
            enter_threshold=self.enter_threshold,
            exit_threshold=self.exit_threshold,
            stop_loss=self.stop_loss
        )
        
        current_signal = signals.iloc[-1] if not signals.empty else 0
        
        # ì‹ í˜¸ í•´ì„
        if current_signal == 1:
            signal_type = "ENTER_LONG"
            direction = f"Long {asset1}, Short {asset2}"
        elif current_signal == -1:
            signal_type = "ENTER_SHORT"
            direction = f"Short {asset1}, Long {asset2}"
        else:
            signal_type = "EXIT_OR_WAIT"
            direction = "Exit or Wait"
        
        return {
            'status': 'success',
            'pair': f"{asset1}-{asset2}",
            'signal_type': signal_type,
            'direction': direction,
            'current_zscore': current_zscore,
            'cluster_id': pair_info['cluster_id'],
            'distance': pair_info['distance'],
            'half_life': pair_info['half_life'],
            'cost_ratio': pair_info['cost_ratio'],
            'method': 'clustering'
        }
    
    def screen_pairs(self, prices: pd.DataFrame, n_pairs: int = 10) -> Tuple[List[Dict], List[Dict]]:
        """
        ì „ì²´ í˜ì–´ ìŠ¤í¬ë¦¬ë‹ ë° ì‹ í˜¸ ìƒì„±
        
        Returns:
            (enter_signals, watch_signals): ì§„ì… ì‹ í˜¸ì™€ ê´€ì°° ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸
        """
        # í˜ì–´ ì„ ì •
        selected_pairs = self.select_pairs(prices, n_pairs * 2)
        
        enter_signals = []
        watch_signals = []
        
        for pair_info in selected_pairs:
            signal_result = self.generate_signals(prices, pair_info)
            
            if signal_result['status'] != 'success':
                continue
                
            current_z = abs(signal_result['current_zscore'])
            
            # ì§„ì… ì‹ í˜¸ (|z| >= 2.0)
            if current_z >= self.enter_threshold:
                enter_signals.append(signal_result)
            # ê´€ì°° ëŒ€ìƒ (1.5 <= |z| < 2.0)
            elif 1.5 <= current_z < self.enter_threshold:
                watch_signals.append(signal_result)
        
        # ê±°ë¦¬ê°€ ê°€ê¹Œìš´ ìˆœìœ¼ë¡œ ì •ë ¬ (í´ëŸ¬ìŠ¤í„° ë‚´ ìœ ì‚¬ì„± ë†’ì€ ìˆœ)
        enter_signals.sort(key=lambda x: x['distance'])
        watch_signals.sort(key=lambda x: x['distance'])
        
        return enter_signals[:n_pairs], watch_signals[:n_pairs]

def main():
    """
    í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© ì‹¤í–‰ ì˜ˆì œ
    """
    # ë°ì´í„° ë¡œë”©
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    file_path = os.path.join(project_root, "data", "MU Price(BBG).csv")
    prices = load_data(file_path)
    
    # í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© ê°ì²´ ìƒì„±
    clustering_trader = ClusteringPairTrading(
        formation_window=252,      # 1ë…„
        signal_window=60,          # 3ê°œì›”
        enter_threshold=2.0,
        exit_threshold=0.5,
        stop_loss=3.0,
        min_half_life=5,
        max_half_life=60,
        min_cost_ratio=5.0,
        n_clusters=8,              # 8ê°œ í´ëŸ¬ìŠ¤í„°
        clustering_method='kmeans'  # K-Means ë°©ë²•
    )
    
    # í´ëŸ¬ìŠ¤í„°ë§ ìš”ì•½ ì •ë³´
    cluster_summary = clustering_trader.get_cluster_summary(prices)
    
    print("=" * 70)
    print("í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ í˜ì–´íŠ¸ë ˆì´ë”© ì‹ í˜¸")
    print("=" * 70)
    
    print(f"\nğŸ¯ í´ëŸ¬ìŠ¤í„° ìš”ì•½ ({len(cluster_summary)}ê°œ):")
    print("-" * 50)
    for cluster_id, info in cluster_summary.items():
        print(f"í´ëŸ¬ìŠ¤í„° {cluster_id}: {info['n_assets']}ê°œ ìì‚°")
        print(f"  ìì‚°: {', '.join(info['assets'][:3])}{'...' if len(info['assets']) > 3 else ''}")
        print(f"  í‰ê·  ë³€ë™ì„±: {info['avg_volatility']:.4f} | í‰ê·  ë² íƒ€: {info['avg_beta']:.3f}")
        print()
    
    # í˜ì–´ ìŠ¤í¬ë¦¬ë‹
    enter_list, watch_list = clustering_trader.screen_pairs(prices, n_pairs=10)
    
    print(f"\nğŸ“ˆ ì§„ì… ì‹ í˜¸ ({len(enter_list)}ê°œ):")
    print("-" * 60)
    for i, signal in enumerate(enter_list, 1):
        print(f"{i:2d}. {signal['pair']:20s} | {signal['direction']:25s}")
        print(f"     Z-Score: {signal['current_zscore']:6.2f} | í´ëŸ¬ìŠ¤í„°: {signal['cluster_id']}")
        print(f"     ê±°ë¦¬: {signal['distance']:6.3f} | Half-Life: {signal['half_life']:4.1f}D")
        print(f"     Cost Ratio: {signal['cost_ratio']:5.1f}")
        print()
    
    print(f"\nğŸ‘€ ê´€ì°° ëŒ€ìƒ ({len(watch_list)}ê°œ):")
    print("-" * 60)
    for i, signal in enumerate(watch_list, 1):
        print(f"{i:2d}. {signal['pair']:20s} | Z-Score: {signal['current_zscore']:6.2f}")
        print(f"     í´ëŸ¬ìŠ¤í„°: {signal['cluster_id']} | ê±°ë¦¬: {signal['distance']:6.3f}")
        print(f"     Half-Life: {signal['half_life']:4.1f}D | Cost Ratio: {signal['cost_ratio']:5.1f}")
        print()

if __name__ == "__main__":
    main()