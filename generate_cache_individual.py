"""
ê°œë³„ ë°©ë²•ë¡  ìºì‹œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ê° ë°©ë²•ë¡ ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ìºì‹œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒ
"""
import os
import sys
import pickle
import argparse
from datetime import datetime
import importlib.util

def import_module_from_file(file_path, module_name):
    """ë™ì  ëª¨ë“ˆ import"""
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module

# ê³µí†µ ìœ í‹¸ë¦¬í‹° import
common_utils = import_module_from_file("utils/common_utils.py", "common_utils")
cache_utils = import_module_from_file("utils/cache_utils.py", "cache_utils")

def generate_euclidean_cache():
    """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import
        euclidean_module = import_module_from_file("methods/1_euclidean_distance_pairs.py", "euclidean_pairs")
        EuclideanDistancePairTrading = euclidean_module.EuclideanDistancePairTrading
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('euclidean')
        
        trader = EuclideanDistancePairTrading(
            formation_window=default_params['formation_window'],
            signal_window=default_params['signal_window'], 
            enter_threshold=default_params['enter_threshold'],
            exit_threshold=default_params['exit_threshold'],
            stop_loss=default_params['stop_loss'],
            min_half_life=default_params['min_half_life'],
            max_half_life=default_params['max_half_life'],
            min_cost_ratio=default_params['min_cost_ratio'],
            transaction_cost=default_params['transaction_cost']
        )
        
        enter_list, watch_list = trader.screen_pairs(prices, n_pairs=20)
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'euclidean'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "euclidean_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… ìœ í´ë¦¬ë“œ ê±°ë¦¬ ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def generate_ssd_cache():
    """SSD ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” SSD ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import  
        ssd_module = import_module_from_file("methods/2_ssd_pairs.py", "ssd_pairs")
        SSDPairTrading = ssd_module.SSDPairTrading
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('ssd')
        
        trader = SSDPairTrading(
            formation_window=default_params['formation_window'],
            signal_window=default_params['signal_window'],
            enter_threshold=default_params['enter_threshold'],
            exit_threshold=default_params['exit_threshold'], 
            stop_loss=default_params['stop_loss'],
            min_half_life=default_params['min_half_life'],
            max_half_life=default_params['max_half_life'],
            min_cost_ratio=default_params['min_cost_ratio'],
            transaction_cost=default_params['transaction_cost']
        )
        
        enter_list, watch_list = trader.screen_pairs(prices, n_pairs=20)
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'ssd'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "ssd_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… SSD ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ SSD ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def generate_cointegration_cache():
    """ê³µì ë¶„ ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” ê³µì ë¶„ ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import
        cointegration_module = import_module_from_file("methods/3_cointegration_pairs.py", "cointegration_pairs")
        CointegrationPairTrading = cointegration_module.CointegrationPairTrading
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('cointegration')
        
        trader = CointegrationPairTrading(
            formation_window=default_params['formation_window'],
            signal_window=default_params['signal_window'],
            enter_threshold=default_params['enter_threshold'],
            exit_threshold=default_params['exit_threshold'],
            stop_loss=default_params['stop_loss'],
            min_half_life=default_params['min_half_life'],
            max_half_life=default_params['max_half_life'],
            min_cost_ratio=default_params['min_cost_ratio'],
            max_pvalue=default_params['max_pvalue']
        )
        
        enter_list, watch_list = trader.screen_pairs(prices, n_pairs=20)
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'cointegration'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "cointegration_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… ê³µì ë¶„ ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ê³µì ë¶„ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def generate_regime_cache():
    """ìƒê´€ê´€ê³„ ë ˆì§ ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” ìƒê´€ê´€ê³„ ë ˆì§ ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import
        regime_module = import_module_from_file("methods/4_correlation_regime_pairs.py", "correlation_regime_pairs")
        CorrelationRegimePairTrading = regime_module.CorrelationRegimePairTrading
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('regime')
        
        trader = CorrelationRegimePairTrading(
            formation_window=default_params['formation_window'],
            signal_window=default_params['signal_window'],
            long_corr_window=default_params['long_corr_window'],
            short_corr_window=default_params['short_corr_window'],
            enter_threshold=default_params['enter_threshold'],
            exit_threshold=default_params['exit_threshold'],
            stop_loss=default_params['stop_loss'],
            min_half_life=default_params['min_half_life'],
            max_half_life=default_params['max_half_life'],
            min_cost_ratio=default_params['min_cost_ratio'],
            min_delta_corr=default_params['min_delta_corr']
        )
        
        enter_list, watch_list = trader.screen_pairs(prices, n_pairs=20)
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'regime'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "regime_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… ìƒê´€ê´€ê³„ ë ˆì§ ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ìƒê´€ê´€ê³„ ë ˆì§ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def generate_ou_cache():
    """OU í‰ê· íšŒê·€ ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” OU í‰ê· íšŒê·€ ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import
        ou_module = import_module_from_file("methods/5_ou_mean_reversion_pairs.py", "ou_pairs")
        OUMeanReversionPairTrading = ou_module.OUMeanReversionPairTrading
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('ou')
        
        trader = OUMeanReversionPairTrading(
            formation_window=default_params['formation_window'],
            signal_window=default_params['signal_window'],
            enter_threshold=default_params['enter_threshold'],
            exit_threshold=default_params['exit_threshold'],
            stop_loss=default_params['stop_loss'],
            min_half_life=default_params['min_half_life'],
            max_half_life=default_params['max_half_life'],
            min_cost_ratio=default_params['min_cost_ratio'],
            min_mean_reversion_speed=default_params['min_mean_reversion_speed']
        )
        
        enter_list, watch_list = trader.screen_pairs(prices, n_pairs=20)
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'ou'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "ou_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… OU í‰ê· íšŒê·€ ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ OU í‰ê· íšŒê·€ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def generate_clustering_cache():
    """í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import
        clustering_module = import_module_from_file("methods/6_clustering_pairs.py", "clustering_pairs")
        ClusteringPairTrading = clustering_module.ClusteringPairTrading
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('clustering')
        
        trader = ClusteringPairTrading(
            formation_window=default_params['formation_window'],
            signal_window=default_params['signal_window'],
            enter_threshold=default_params['enter_threshold'],
            exit_threshold=default_params['exit_threshold'],
            stop_loss=default_params['stop_loss'],
            min_half_life=default_params['min_half_life'],
            max_half_life=default_params['max_half_life'],
            min_cost_ratio=default_params['min_cost_ratio'],
            n_clusters=default_params['n_clusters'],
            clustering_method=default_params['clustering_method']
        )
        
        enter_list, watch_list = trader.screen_pairs(prices, n_pairs=20)
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'clustering'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "clustering_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… í´ëŸ¬ìŠ¤í„°ë§ ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def generate_copula_cache():
    """ì½”í“°ë¼ ë°©ë²•ë¡  ìºì‹œ ìƒì„±"""
    print("ğŸ” ì½”í“°ë¼ ë¶„ì„ ìºì‹œ ìƒì„± ì‹œì‘...")
    
    try:
        # ëª¨ë“ˆ import
        copula_module = import_module_from_file("methods/7_copula_rank_correlation_pairs.py", "copula_pairs")
        CopulaBasedPairScreening = copula_module.CopulaBasedPairScreening
        
        # ë°ì´í„° ë¡œë”©
        file_path = "data/MU Price(BBG).csv"
        prices = common_utils.load_data(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(prices.columns)}ê°œ ìì‚°, {len(prices)}ì¼")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        default_params = cache_utils.get_default_parameters('copula')
        
        # ìƒˆë¡œìš´ ê´€ëŒ€í•œ ì„¤ì •ìœ¼ë¡œ CopulaBasedPairScreening ì‚¬ìš©
        screener = CopulaBasedPairScreening()  # ê¸°ë³¸ê°’ ì‚¬ìš© (ì´ë¯¸ ê´€ëŒ€í•˜ê²Œ ì„¤ì •ë¨)
        
        enter_list = screener.select_pairs(prices, n_pairs=20)
        watch_list = []  # CopulaBasedPairScreeningì—ì„œëŠ” watch_list ë¶„ë¦¬ ë¡œì§ì´ ë‹¤ë¦„
        
        # ìºì‹œ ë°ì´í„° ìƒì„±
        cache_data = {
            'generated_at': datetime.now().isoformat(),
            'data_date': prices.index[-1].isoformat(),
            'parameters': default_params,
            'enter_signals': enter_list,
            'watch_signals': watch_list,
            'method': 'copula'
        }
        
        # ìºì‹œ íŒŒì¼ ì €ì¥
        cache_dir = "cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, "copula_default.pkl")
        
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"âœ… ì½”í“°ë¼ ìºì‹œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {cache_file}")
        print(f"ğŸ“ˆ ì§„ì… ì‹ í˜¸: {len(enter_list)}ê°œ, ê´€ì°° ëŒ€ìƒ: {len(watch_list)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ì½”í“°ë¼ ìºì‹œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def main():
    parser = argparse.ArgumentParser(description='ê°œë³„ ë°©ë²•ë¡  ìºì‹œ ìƒì„±')
    parser.add_argument('method', nargs='?', 
                       choices=['euclidean', 'ssd', 'cointegration', 'regime', 'ou', 'clustering', 'copula', 'all'],
                       help='ìƒì„±í•  ìºì‹œ ë°©ë²•ë¡  (all: ëª¨ë“  ë°©ë²•ë¡ )')
    
    args = parser.parse_args()
    
    if not args.method:
        print("ğŸ”¥ ê°œë³„ ë°©ë²•ë¡  ìºì‹œ ìƒì„± ë„êµ¬")
        print("-" * 40)
        print("ì‚¬ìš©ë²•: python generate_cache_individual.py [METHOD]")
        print()
        print("METHOD ì˜µì…˜:")
        print("  euclidean     - ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë°©ë²•ë¡ ")
        print("  ssd           - SSD ë°©ë²•ë¡ ") 
        print("  cointegration - ê³µì ë¶„ ë°©ë²•ë¡ ")
        print("  regime        - ìƒê´€ê´€ê³„ ë ˆì§ ë°©ë²•ë¡ ")
        print("  ou            - OU í‰ê· íšŒê·€ ë°©ë²•ë¡ ")
        print("  clustering    - í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•ë¡ ")
        print("  copula        - ì½”í“°ë¼ ë°©ë²•ë¡ ")
        print("  all           - ëª¨ë“  ë°©ë²•ë¡  (ìˆœì°¨ ì‹¤í–‰)")
        print()
        print("ì˜ˆì‹œ:")
        print("  python generate_cache_individual.py regime")
        print("  python generate_cache_individual.py all")
        return
    
    print(f"ğŸš€ {args.method} ë°©ë²•ë¡  ìºì‹œ ìƒì„± ì‹œì‘")
    print("=" * 50)
    
    start_time = datetime.now()
    
    if args.method == 'euclidean':
        generate_euclidean_cache()
    elif args.method == 'ssd':
        generate_ssd_cache()
    elif args.method == 'cointegration':
        generate_cointegration_cache()
    elif args.method == 'regime':
        generate_regime_cache()
    elif args.method == 'ou':
        generate_ou_cache()
    elif args.method == 'clustering':
        generate_clustering_cache()
    elif args.method == 'copula':
        generate_copula_cache()
    elif args.method == 'all':
        print("ğŸ“¦ ëª¨ë“  ë°©ë²•ë¡  ìºì‹œ ìˆœì°¨ ìƒì„±...")
        methods = ['euclidean', 'ssd', 'cointegration', 'regime', 'ou', 'clustering', 'copula']
        
        for i, method in enumerate(methods, 1):
            print(f"\n{'='*50}")
            print(f"ğŸ”„ {i}/{len(methods)}: {method.upper()} ë°©ë²•ë¡ ")
            print(f"{'='*50}")
            
            method_start = datetime.now()
            
            if method == 'euclidean':
                generate_euclidean_cache()
            elif method == 'ssd':
                generate_ssd_cache()
            elif method == 'cointegration':
                generate_cointegration_cache()
            elif method == 'regime':
                generate_regime_cache()
            elif method == 'ou':
                generate_ou_cache()
            elif method == 'clustering':
                generate_clustering_cache()
            elif method == 'copula':
                generate_copula_cache()
            
            method_end = datetime.now()
            method_duration = method_end - method_start
            print(f"â±ï¸ {method} ì™„ë£Œ ì‹œê°„: {method_duration.total_seconds():.1f}ì´ˆ")
    
    end_time = datetime.now()
    total_duration = end_time - start_time
    
    print(f"\nğŸ‰ ì „ì²´ ì‘ì—… ì™„ë£Œ!")
    print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_duration.total_seconds():.1f}ì´ˆ")
    
    # ìƒì„±ëœ ìºì‹œ íŒŒì¼ ì •ë³´ í‘œì‹œ
    cache_info = cache_utils.get_cache_info()
    print(f"\nğŸ“Š ìƒì„±ëœ ìºì‹œ íŒŒì¼ í˜„í™©:")
    for method, info in cache_info.items():
        if info['exists']:
            print(f"  âœ… {method}: {info['enter_count']}ê°œ ì§„ì…, {info['watch_count']}ê°œ ê´€ì°°")
        else:
            print(f"  âŒ {method}: íŒŒì¼ ì—†ìŒ")

if __name__ == "__main__":
    main()